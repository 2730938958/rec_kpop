from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from neo4j import GraphDatabase  # å¯¼å…¥Neo4jé©±åŠ¨
import torch
import asyncio
from langchain_community.utilities import SerpAPIWrapper
import os
os.environ['SERPAPI_API_KEY'] = '5f637d55472a8b1a905c0648dd0b79637288ca2e28c5a35bd248c38b7d921ceb'
# ---------------------- 1. åˆå§‹åŒ–FastAPIå’ŒCORSé…ç½® ----------------------
app = FastAPI(title="Qwen LLM + Neo4j Service")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒæ›¿æ¢ä¸ºå…·ä½“å‰ç«¯åŸŸå
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ---------------------- 2. å®šä¹‰è¯·æ±‚æ¨¡å‹ ----------------------
class LLMRequest(BaseModel):
    prompt: str  # ç”¨æˆ·è¾“å…¥ï¼ˆå«â€œçŸ¥è¯†åº“â€åˆ™è§¦å‘Neo4jï¼‰
    model: str = "Qwen/Qwen2.5-7B-Instruct"
    temperature: float = 0.7
    max_new_tokens: int = 512


# ---------------------- 3. Neo4jé…ç½®ä¸æ£€ç´¢å‡½æ•°ï¼ˆæ–°å¢ï¼‰ ----------------------
# Neo4jè¿æ¥ä¿¡æ¯ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…é…ç½®ï¼‰
NEO4J_URI = "neo4j+s://30acc171.databases.neo4j.io"
NEO4J_AUTH = ("neo4j", "A_Arjzc6q8TkRAC0wtSULmanpNpTLSmCJqtXmNrtyMY")
NEO4J_DATABASE = "neo4j"

def load_singer_list(file_path):
    singer_set = set()  # ç”¨setæ¯”listå¿«ï¼Œé¿å…é‡å¤åŒ¹é…
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            singer = line.strip()  # å»é™¤æ¯è¡Œçš„æ¢è¡Œç¬¦ã€ç©ºæ ¼
            if singer:  # è·³è¿‡ç©ºè¡Œ
                singer_set.add(singer.lower())  # è½¬å°å†™ï¼Œå®ç°ä¸åŒºåˆ†å¤§å°å†™åŒ¹é…
    return singer_set

def detect_singer(input_text, singer_set):
    input_text_lower = input_text.lower()  # è¾“å…¥æ–‡æœ¬ä¹Ÿè½¬å°å†™
    detected_singers = []
    for singer in singer_set:
        if singer in input_text_lower:  # å­—ç¬¦ä¸²åŒ…å«åŒ¹é…ï¼ˆå¦‚â€œæˆ‘å–œæ¬¢itzyâ€ä¼šåŒ¹é…åˆ°â€œitzyâ€ï¼‰
            detected_singers.append(singer.title())  # è½¬å›é¦–å­—æ¯å¤§å†™ï¼Œè¾“å‡ºæ ‡å‡†å
    return detected_singers

def retrieve_from_neo4j(artist_name: str = "ITZY") -> list[dict]:
    """
    ä»Neo4jæ£€ç´¢ç›¸å…³èŠ‚ç‚¹æ•°æ®ï¼ˆä»…å½“ç”¨æˆ·è¾“å…¥å«â€œçŸ¥è¯†åº“â€æ—¶è°ƒç”¨ï¼‰
    :param artist_name: æ£€ç´¢çš„ç›®æ ‡è‰ºäººï¼ˆå¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
    :return: ç›¸å…³èŠ‚ç‚¹çš„KVåˆ—è¡¨ï¼ˆç©ºåˆ—è¡¨è¡¨ç¤ºæ£€ç´¢å¤±è´¥/æ— æ•°æ®ï¼‰
    """
    driver = None
    related_li = []
    try:
        # å»ºç«‹Neo4jè¿æ¥
        driver = GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH)
        driver.verify_connectivity()  # éªŒè¯è¿æ¥æœ‰æ•ˆæ€§
        print("âœ… Neo4jè¿æ¥æˆåŠŸï¼Œå¼€å§‹æ£€ç´¢æ•°æ®")

        # æ‰§è¡ŒCypheræŸ¥è¯¢ï¼ˆåŒ¹é…ç›®æ ‡è‰ºäººçš„ç›¸å…³èŠ‚ç‚¹ï¼Œå–å‰5æ¡é¿å…æ•°æ®è¿‡è½½ï¼‰
        records, summary, keys = driver.execute_query("""
            MATCH (ITZY:Artist {artistName: "ITZY"})-[r]-(related)
            RETURN ITZY, r, related
            """,
            database_="neo4j".replace('ITZY', artist_name),)

        related_li = []
        # Loop through results and do something with them
        for record in records[:5]:
            related_li.append({
                'artistName': record.data()['related']['artistName'],
                'topTrack': record.data()['related']['topTrack'],
                'topTrackLink': record.data()['related']['topTrackLink'],
                'topTrackAlbum': record.data()['related']['topTrackAlbum'],
                'topTrackAlbumLink': record.data()['related']['topTrackAlbumLink'],
            })  # obtain record as dict

        print(f"âœ… Neo4jæ£€ç´¢å®Œæˆï¼Œè·å–åˆ° {len(related_li)} ä¸ªç›¸å…³èŠ‚ç‚¹")
        return related_li

    except Exception as e:
        print(f"âŒ Neo4jæ£€ç´¢å¤±è´¥: {str(e)}")
        return []  # æ£€ç´¢å¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸é˜»æ–­LLMæµç¨‹

    finally:
        # ç¡®ä¿å…³é—­è¿æ¥ï¼Œé¿å…èµ„æºæ³„æ¼
        if driver:
            driver.close()
            print("âœ… Neo4jè¿æ¥å·²å…³é—­")


# ---------------------- 4. LLMæ¨¡å‹åŠ è½½ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰ ----------------------
model_name = "Qwen/Qwen2.5-7B-Instruct"
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)
singer_list = load_singer_list("singer.txt")
print("å¼€å§‹åŠ è½½Qwenæ¨¡å‹...")
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto",
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {model.device}")


# ---------------------- 5. æ–‡æœ¬ç”Ÿæˆå‡½æ•°ï¼ˆæ–°å¢Neo4jæ•°æ®æ•´åˆé€»è¾‘ï¼‰ ----------------------
def generate_text(text: str, temperature: float, max_new_tokens: int) -> str:
    """åŸæœ‰æ–‡æœ¬ç”Ÿæˆé€»è¾‘ï¼Œä¿æŒä¸å˜"""
    model_inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True).to(model.device)
    generated_ids = model.generate(
        **model_inputs,
        max_new_tokens=max_new_tokens,
        do_sample=temperature > 0,
        temperature=temperature,
        num_return_sequences=1,
        pad_token_id=tokenizer.pad_token_id  # é¿å…è­¦å‘Š
    )
    generated_ids_slice = generated_ids[0][len(model_inputs.input_ids[0]):]
    return tokenizer.decode(generated_ids_slice, skip_special_tokens=True)


def build_prompt_with_neo4j(user_prompt: str, neo4j_data: list[dict], singer) -> str:
    """
    æ•´åˆNeo4jæ•°æ®æ„å»ºæ–°Promptï¼ˆä»…å½“æœ‰Neo4jæ•°æ®æ—¶è°ƒç”¨ï¼‰
    :param user_prompt: ç”¨æˆ·åŸå§‹è¾“å…¥
    :param neo4j_data: Neo4jæ£€ç´¢åˆ°çš„KVåˆ—è¡¨
    :return: åŒ…å«çŸ¥è¯†åº“ä¿¡æ¯çš„å®Œæ•´Prompt
    """
    # æ ¼å¼åŒ–Neo4jæ•°æ®ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€ä¸ªKVï¼‰
    neo4j_info = ""
    for idx, node in enumerate(neo4j_data, 1):
        neo4j_info += f"\nã€è‰ºäºº{idx}ã€‘\n"
        for key, value in node.items():
            neo4j_info += f"- {key}ï¼š{value}\n"

    # ç»„è£…å«çŸ¥è¯†åº“çš„Prompt
    print(neo4j_info)
    full_prompt = f"""
    ä½ æ˜¯ä¸“ä¸šçš„K-PopéŸ³ä¹åŠ©æ‰‹ï¼Œç”¨æˆ·æƒ³è®©ä½ æ¨èå‡ ä¸ªkpopæ­Œæ‰‹ï¼Œä½ éœ€åŸºäºä»¥ä¸‹ã€çŸ¥è¯†åº“æ­Œæ‰‹ä¿¡æ¯ã€‘è¿›è¡Œæ¨èï¼Œè¦æ±‚å›ç­”è‡ªç„¶ï¼Œç”¨è‹±è¯­å›ç­”ï¼š
    
    ã€çŸ¥è¯†åº“æ­Œæ‰‹ä¿¡æ¯ã€‘
    {neo4j_info}

    
    """
    return full_prompt  # å»é™¤å¤šä½™ç©ºæ ¼


# ---------------------- 6. APIç«¯ç‚¹ï¼ˆæ ¸å¿ƒï¼šåˆ¤æ–­æ˜¯å¦è§¦å‘Neo4jï¼‰ ----------------------
@app.post("/api/llm")
async def generate_response(request: LLMRequest):
    try:
        user_prompt = request.prompt.strip()
        neo4j_data = []  # å­˜å‚¨Neo4jæ•°æ®ï¼ˆé»˜è®¤ç©ºï¼‰
        final_prompt = user_prompt  # æœ€ç»ˆä¼ å…¥LLMçš„Promptï¼ˆé»˜è®¤ç”¨æˆ·åŸå§‹è¾“å…¥ï¼‰

        # ---------------------- å…³é”®åˆ¤æ–­ï¼šç”¨æˆ·è¾“å…¥æ˜¯å¦å«â€œçŸ¥è¯†åº“â€ ----------------------
        if "knowledge base" in user_prompt:
            print("ğŸ” æ£€æµ‹åˆ°ç”¨æˆ·è¾“å…¥å«â€œçŸ¥è¯†åº“â€ï¼Œè°ƒç”¨Neo4jæ£€ç´¢")
            singer = detect_singer(user_prompt, singer_list)

            singer = singer[0] if len(singer) > 0 else "ITZY"

            # 1. è°ƒç”¨Neo4jè·å–æ•°æ®ï¼ˆè¿™é‡Œé»˜è®¤æ£€ç´¢ITZYç›¸å…³ï¼Œå¯æ ¹æ®éœ€æ±‚åŠ¨æ€è°ƒæ•´è‰ºäººï¼‰
            neo4j_data = retrieve_from_neo4j(artist_name=singer)
            # 2. è‹¥æ£€ç´¢åˆ°æ•°æ®ï¼Œæ„å»ºå«çŸ¥è¯†åº“çš„Promptï¼›æ— æ•°æ®åˆ™ç”¨åŸå§‹Prompt
            if neo4j_data:
                final_prompt = build_prompt_with_neo4j(user_prompt, neo4j_data, singer)
            else:
                final_prompt = f"{user_prompt}\nï¼ˆæ³¨ï¼šçŸ¥è¯†åº“æš‚æœªè·å–åˆ°ç›¸å…³æ•°æ®ï¼Œå°†åŸºäºé»˜è®¤çŸ¥è¯†å›ç­”ï¼‰"

        elif "search" in user_prompt or "internet" in user_prompt:
            search = SerpAPIWrapper()
            # è¿è¡Œæœç´¢æŸ¥è¯¢
            result = search.run(user_prompt)
            final_prompt = f"ç”¨æˆ·ç°åœ¨æœ‰ä»¥ä¸‹è”ç½‘æœç´¢è¦æ±‚[{user_prompt}]\nä»¥ä¸‹æ˜¯è”ç½‘æœç´¢åˆ°çš„å†…å®¹ï¼š{result},è¯·ç›´æ¥ç”Ÿæˆä¸€æ®µç»™ç”¨æˆ·çš„ç­”æ¡ˆ"

        else:
            print("ç›´æ¥ä½¿ç”¨LLMé»˜è®¤å›ç­”ing")

        # ---------------------- æ„å»ºå¯¹è¯æ¨¡æ¿å¹¶è°ƒç”¨LLM ----------------------
        # ç”Ÿæˆç¬¦åˆQwenæ ¼å¼çš„å¯¹è¯æ¶ˆæ¯
        messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": final_prompt}
        ]
        # åº”ç”¨èŠå¤©æ¨¡æ¿
        text = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )

        # å¼‚æ­¥è°ƒç”¨LLMç”Ÿæˆå›å¤
        loop = asyncio.get_event_loop()
        response_text = await loop.run_in_executor(
            None,
            generate_text,
            text,
            request.temperature,
            request.max_new_tokens
        )
        print(f'ğŸ“ æ¨¡å‹ç”Ÿæˆçš„ç­”å¤ï¼š{response_text}')

        # ---------------------- è¿”å›ç»“æœï¼ˆåŒ…å«æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“çš„æ ‡è¯†ï¼‰ ----------------------
        return {
            "response": response_text,
            "recommendations": neo4j_data,  # å‰ç«¯å¯ç›´æ¥ç”¨Neo4jæ•°æ®æ¸²æŸ“
            "used_knowledge_base": "çŸ¥è¯†åº“" in user_prompt,  # æ ‡è¯†æ˜¯å¦ä½¿ç”¨äº†çŸ¥è¯†åº“
            "knowledge_base_count": len(neo4j_data)  # çŸ¥è¯†åº“è¿”å›çš„èŠ‚ç‚¹æ•°é‡
        }

    except Exception as e:
        error_msg = f"æœåŠ¡å¤„ç†å¤±è´¥: {str(e)}"
        print(error_msg)
        raise HTTPException(status_code=500, detail=error_msg)


# ---------------------- 7. æ ¹è·¯å¾„æµ‹è¯• ----------------------
@app.get("/")
async def root():
    return {
        "message": "Qwen LLM + Neo4j Service is running",
        "tip": "ç”¨æˆ·è¾“å…¥å«â€œçŸ¥è¯†åº“â€å…³é”®è¯æ—¶ï¼Œå°†è°ƒç”¨Neo4jæ£€ç´¢æ•°æ®"
    }


# ---------------------- 8. å¯åŠ¨æœåŠ¡ ----------------------
if __name__ == "__main__":
    import uvicorn

    # å•è¿›ç¨‹æ¨¡å¼ï¼ˆç¡®ä¿è°ƒè¯•æ–­ç‚¹ç”Ÿæ•ˆï¼‰
    uvicorn.run(app, host="0.0.0.0", port=7899, workers=1, reload=False)